{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all_indices = np.load('../data/X_train_all_indices.npy')\n",
    "y_train = np.load('../data/y_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_features = StandardScaler()\n",
    "X_train = scaler_features.fit_transform(X_train_all_indices)\n",
    "\n",
    "scaler_targets = StandardScaler()\n",
    "y_train = scaler_targets.fit_transform(y_train.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_logdir(model_id):\n",
    "    return os.path.join(os.curdir, f'mlp_logs/model_{model_id}')\n",
    "\n",
    "earlystopping_cb = EarlyStopping(monitor='loss', patience=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./cnn_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "model[i] = Sequential([\n",
    "    Dense(10, input_dim=22, activation='relu'),\n",
    "    Dense(5, activation='relu'),\n",
    "    Dense(1),\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'mlp_models/mlp_{i}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "\n",
    "model[i] = Sequential([\n",
    "    Dense(20, input_dim=22, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1),\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'mlp_models/mlp_{i}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "\n",
    "model[i] = Sequential([\n",
    "    Dense(50, input_dim=22, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1),\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'mlp_models/mlp_{i}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 4\n",
    "\n",
    "model[i] = Sequential([\n",
    "    Dense(100, input_dim=22, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(50, input_dim=22, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1),\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'mlp_models/mlp_{i}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "\n",
    "model[i] = Sequential([\n",
    "    Dense(100, input_dim=22, activation='relu'),\n",
    "    Dropout(0.05),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dropout(0.05),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dropout(0.05),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1),\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'mlp_models/mlp_{i}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 6\n",
    "\n",
    "model[i] = Sequential([\n",
    "    Dense(200, input_dim=22, activation='relu'),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1),\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'mlp_models/mlp_{i}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 7\n",
    "\n",
    "model[i] = Sequential([\n",
    "    Dense(200, input_dim=22, activation='relu'),\n",
    "    Dropout(0.05),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.05),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dropout(0.05),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1),\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'mlp_models/mlp_{i}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 8\n",
    "\n",
    "model[i] = Sequential([\n",
    "    Dense(200, input_dim=22, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1),\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'mlp_models/mlp_{i}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 9\n",
    "\n",
    "model[i] = Sequential([\n",
    "    Dense(200, input_dim=22, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1),\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'mlp_models/mlp_{i}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10\n",
    "\n",
    "model[i] = Sequential([\n",
    "    Dense(200, input_dim=22, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1),\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'mlp_models/mlp_{i}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 11\n",
    "\n",
    "model[i] = Sequential([\n",
    "    Dense(200, input_dim=22, activation='relu'),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1),\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'mlp_models/mlp_{i}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 12\n",
    "\n",
    "model[i] = Sequential([\n",
    "    Dense(200, input_dim=22, activation='relu'),\n",
    "    Dropout(0.05),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1),\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'mlp_models/mlp_{i}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 13\n",
    "\n",
    "model[i] = Sequential([\n",
    "    Dense(400, input_dim=22, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(200, activation='relu'),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1),\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'mlp_models/mlp_{i}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 14\n",
    "\n",
    "model[i] = Sequential([\n",
    "    Dense(100, input_dim=22, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1),\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'mlp_models/mlp_{i}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 15\n",
    "\n",
    "model[i] = Sequential([\n",
    "    Dense(100, input_dim=22, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1),\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'mlp_models/mlp_{i}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 16\n",
    "\n",
    "model[i] = Sequential([\n",
    "    Dense(50, input_dim=22, activation='relu'),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1),\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'mlp_models/mlp_{i}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 17\n",
    "\n",
    "model[i] = Sequential([\n",
    "    Dense(50, input_dim=22, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1),\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'mlp_models/mlp_{i}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 18\n",
    "\n",
    "model[i] = Sequential([\n",
    "    Dense(50, input_dim=22, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1),\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'mlp_models/mlp_{i}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 19\n",
    "\n",
    "model[i] = Sequential([\n",
    "    Dense(50, input_dim=22, activation='relu'),\n",
    "    Dropout(0.05),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1),\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'mlp_models/mlp_{i}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 20\n",
    "\n",
    "model[i] = Sequential([\n",
    "    Dense(50, input_dim=22, activation='relu'),\n",
    "    Dropout(0.05),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dropout(0.05),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1),\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'mlp_models/mlp_{i}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 21\n",
    "\n",
    "model[i] = Sequential([\n",
    "    Dense(50, input_dim=22, activation='relu'),\n",
    "    Dropout(0.075),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1),\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'mlp_models/mlp_{i}.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: Increasing the number of tunable parameters further than 50 neurons in the first hidden layer is not beneficial. A bit of dropout is needed to counteract overfitting."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting model 21 as best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[21].save('../models/mlp.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
