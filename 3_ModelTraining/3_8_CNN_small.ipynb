{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer, Dense, Flatten, Conv2D, MaxPool2D, Dropout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_train = np.load('../data/indices_train.npy')\n",
    "\n",
    "X_full = np.stack(list(map(lambda index: np.load(f'../data/images_train/image_{index:03d}.npy'), range(40))))\n",
    "y = np.stack(list(map(lambda index: np.load(f'../data/masks_train/mask_{index:03d}.npy'), range(40))))\n",
    "# The labels do not change\n",
    "y_train = y[indices_train[:, 0], 0, indices_train[:, 2], indices_train[:, 3]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 5x5 Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNEL_RADIUS = 2\n",
    "KERNEL_SIZE = KERNEL_RADIUS*2 + 1\n",
    "\n",
    "expanded_indices_train = np.repeat(indices_train, (KERNEL_SIZE*KERNEL_SIZE), axis=0)\n",
    "\n",
    "offsets = np.array([(i, j) for i in range(-KERNEL_RADIUS, KERNEL_RADIUS+1) for j in range(-KERNEL_RADIUS, KERNEL_RADIUS+1)])\n",
    "\n",
    "# Compute new width and height indices with offsets and ensure they're within valid bounds\n",
    "expanded_indices_train[:, 2] = np.clip(\n",
    "    np.repeat(indices_train[:, 2], (KERNEL_SIZE*KERNEL_SIZE)) + np.tile(offsets[:, 0], len(indices_train)), 0, 1023\n",
    ")\n",
    "expanded_indices_train[:, 3] = np.clip(\n",
    "    np.repeat(indices_train[:, 3], (KERNEL_SIZE*KERNEL_SIZE)) + np.tile(offsets[:, 1], len(indices_train)), 0, 1023\n",
    ")\n",
    "\n",
    "X_train_5x5 = X_full[expanded_indices_train[:, 0], :, expanded_indices_train[:, 2], expanded_indices_train[:, 3]]\n",
    "X_train_5x5 = np.reshape(X_train_5x5, ((X_train_5x5.shape[0] // (KERNEL_SIZE*KERNEL_SIZE)), KERNEL_SIZE, KERNEL_SIZE, -1))\n",
    "\n",
    "# Calculate the mean and standard deviation of the data\n",
    "mean = np.mean(X_train_5x5)\n",
    "std = np.std(X_train_5x5)\n",
    "# Normalize the data\n",
    "X_train_5x5 = (X_train_5x5 - mean) / std\n",
    "\n",
    "print(X_train_5x5.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 7x7 Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNEL_RADIUS = 3\n",
    "KERNEL_SIZE = KERNEL_RADIUS*2 + 1\n",
    "\n",
    "expanded_indices_train = np.repeat(indices_train, (KERNEL_SIZE*KERNEL_SIZE), axis=0)\n",
    "\n",
    "offsets = np.array([(i, j) for i in range(-KERNEL_RADIUS, KERNEL_RADIUS+1) for j in range(-KERNEL_RADIUS, KERNEL_RADIUS+1)])\n",
    "\n",
    "# Compute new width and height indices with offsets and ensure they're within valid bounds\n",
    "expanded_indices_train[:, 2] = np.clip(\n",
    "    np.repeat(indices_train[:, 2], (KERNEL_SIZE*KERNEL_SIZE)) + np.tile(offsets[:, 0], len(indices_train)), 0, 1023\n",
    ")\n",
    "expanded_indices_train[:, 3] = np.clip(\n",
    "    np.repeat(indices_train[:, 3], (KERNEL_SIZE*KERNEL_SIZE)) + np.tile(offsets[:, 1], len(indices_train)), 0, 1023\n",
    ")\n",
    "\n",
    "X_train_7x7 = X_full[expanded_indices_train[:, 0], :, expanded_indices_train[:, 2], expanded_indices_train[:, 3]]\n",
    "X_train_7x7 = np.reshape(X_train_7x7, ((X_train_7x7.shape[0] // (KERNEL_SIZE*KERNEL_SIZE)), KERNEL_SIZE, KERNEL_SIZE, -1))\n",
    "\n",
    "# Calculate the mean and standard deviation of the data\n",
    "mean = np.mean(X_train_7x7)\n",
    "std = np.std(X_train_7x7)\n",
    "# Normalize the data\n",
    "X_train_7x7 = (X_train_7x7 - mean) / std\n",
    "\n",
    "print(X_train_7x7.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 9x9 Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNEL_RADIUS = 4\n",
    "KERNEL_SIZE = KERNEL_RADIUS*2 + 1\n",
    "\n",
    "expanded_indices_train = np.repeat(indices_train, (KERNEL_SIZE*KERNEL_SIZE), axis=0)\n",
    "\n",
    "offsets = np.array([(i, j) for i in range(-KERNEL_RADIUS, KERNEL_RADIUS+1) for j in range(-KERNEL_RADIUS, KERNEL_RADIUS+1)])\n",
    "\n",
    "# Compute new width and height indices with offsets and ensure they're within valid bounds\n",
    "expanded_indices_train[:, 2] = np.clip(\n",
    "    np.repeat(indices_train[:, 2], (KERNEL_SIZE*KERNEL_SIZE)) + np.tile(offsets[:, 0], len(indices_train)), 0, 1023\n",
    ")\n",
    "expanded_indices_train[:, 3] = np.clip(\n",
    "    np.repeat(indices_train[:, 3], (KERNEL_SIZE*KERNEL_SIZE)) + np.tile(offsets[:, 1], len(indices_train)), 0, 1023\n",
    ")\n",
    "\n",
    "X_train_9x9 = X_full[expanded_indices_train[:, 0], :, expanded_indices_train[:, 2], expanded_indices_train[:, 3]]\n",
    "X_train_9x9 = np.reshape(X_train_9x9, ((X_train_9x9.shape[0] // (KERNEL_SIZE*KERNEL_SIZE)), KERNEL_SIZE, KERNEL_SIZE, -1))\n",
    "\n",
    "# Calculate the mean and standard deviation of the data\n",
    "mean = np.mean(X_train_9x9)\n",
    "std = np.std(X_train_9x9)\n",
    "# Normalize the data\n",
    "X_train_9x9 = (X_train_9x9 - mean) / std\n",
    "\n",
    "print(X_train_9x9.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_logdir(model_id):\n",
    "    return os.path.join(os.curdir, f'cnn_logs/model_{model_id}')\n",
    "\n",
    "earlystopping_cb = keras.callbacks.EarlyStopping(monitor='loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./cnn_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: 5x5 Input, 3x3x3 Kernel, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[5, 5, 10]),\n",
    "    Conv2D(filters=3, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_5x5, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: 5x5 Input, 3x3x8 Kernel, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[5, 5, 10]),\n",
    "    Conv2D(filters=8, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_5x5, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: 5x5 Input, 3x3x12 Kernel, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[5, 5, 10]),\n",
    "    Conv2D(filters=12, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_5x5, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: 5x5 Input, 3x3x8 Kernel, 50 Dense, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 4\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[5, 5, 10]),\n",
    "    Conv2D(filters=8, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_5x5, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5: 5x5 Input, 3x3x8 Kernel, 0.2 Dropout, 50 Dense, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[5, 5, 10]),\n",
    "    Conv2D(filters=8, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.2),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_5x5, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 6: 5x5 Input, 3x3x8 Kernel, 0.1 Dropout, 50 Dense, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 6\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[5, 5, 10]),\n",
    "    Conv2D(filters=8, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.1),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_5x5, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 7: 7x7 Input, 3x3x3 Kernel, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 7\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[7, 7, 10]),\n",
    "    Conv2D(filters=3, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_7x7, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 8: 7x7 Input, 3x3x8 Kernel, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 8\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[7, 7, 10]),\n",
    "    Conv2D(filters=8, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_7x7, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 9: 7x7 Input, 3x3x8 Kernel, 50 Dense, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 9\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[7, 7, 10]),\n",
    "    Conv2D(filters=8, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_7x7, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 10: 7x7 Input, 3x3x8 Kernel, 0.2 Dropout, 50 Dense, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[7, 7, 10]),\n",
    "    Conv2D(filters=8, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.2),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_7x7, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 11: 7x7 Input, 3x3x8 Kernel, 0.1 Dropout, 50 Dense, 0.1 Dropout, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 11\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[7, 7, 10]),\n",
    "    Conv2D(filters=8, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.1),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_7x7, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 12: 7x7 Input, 3x3x12 Kernel, 0.1 Dropout, 100 Dense, 0.1 Dropout, 50 Dense, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 12\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[7, 7, 10]),\n",
    "    Conv2D(filters=12, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.1),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_7x7, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 13: 7x7 Input, 3x3x12 Kernel, 0.2 Dropout, 100 Dense, 0.2 Dropout, 50 Dense, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 13\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[7, 7, 10]),\n",
    "    Conv2D(filters=12, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.2),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_7x7, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 14: 7x7 Input, 3x3x12 Kernel, 20 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 14\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[7, 7, 10]),\n",
    "    Conv2D(filters=12, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_7x7, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 15: 7x7 Input, 3x3x12 Kernel, 0.05 Dropout, 20 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 15\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[7, 7, 10]),\n",
    "    Conv2D(filters=12, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.05),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_7x7, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 16: 7x7 Input, 3x3x12 Kernel, 0.05 Dropout, 40 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 16\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[7, 7, 10]),\n",
    "    Conv2D(filters=12, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.05),\n",
    "    Dense(40, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_7x7, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 17: 7x7 Input, 3x3x12 Kernel, 0.1 Dropout, 80 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 17\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[7, 7, 10]),\n",
    "    Conv2D(filters=12, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.05),\n",
    "    Dense(80, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_7x7, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 18: 7x7 Input, 3x3x12 Kernel, 0.15 Dropout, 120 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 18\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[7, 7, 10]),\n",
    "    Conv2D(filters=12, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.15),\n",
    "    Dense(120, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_7x7, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 19: 9x9 Input, 3x3x3 Kernel, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 19\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[9, 9, 10]),\n",
    "    Conv2D(filters=3, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_9x9, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 20: 9x9 Input, 3x3x8 Kernel, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 20\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[9, 9, 10]),\n",
    "    Conv2D(filters=8, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_9x9, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 21: 9x9 Input, 5x5x8 Kernel, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 21\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[9, 9, 10]),\n",
    "    Conv2D(filters=8, kernel_size=5, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_9x9, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 22: 9x9 Input, 5x5x8 Kernel, 0.2 Dropout, 100 Dense, 0.2 Dropout, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 22\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[9, 9, 10]),\n",
    "    Conv2D(filters=8, kernel_size=5, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.2),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_9x9, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 23: 9x9 Input, 3x3x8 Kernel, 0.1 Dropout, 100 Dense, 0.1 Dropout, 50 Dense, 0.1 Dropout, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 23\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[9, 9, 10]),\n",
    "    Conv2D(filters=8, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.1),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_9x9, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 24: 9x9 Input, 3x3x8 Kernel, 0.2 Dropout, 100 Dense, 0.2 Dropout, 50 Dense, 0.2 Dropout, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 24\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[9, 9, 10]),\n",
    "    Conv2D(filters=8, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.2),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_9x9, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 25: 9x9 Input, 3x3x8 Kernel, 0.3 Dropout, 100 Dense, 0.3 Dropout, 50 Dense, 0.3 Dropout, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 25\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[9, 9, 10]),\n",
    "    Conv2D(filters=8, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.3),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_9x9, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 26: 9x9 Input, 3x3x8 Kernel, 0.1 Dropout, 30 Dense, 0.1 Dropout, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 26\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[9, 9, 10]),\n",
    "    Conv2D(filters=8, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.1),\n",
    "    Dense(30, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_9x9, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 27: 9x9 Input, 3x3x8 Kernel, 3x3x2 Kernel, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 27\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[9, 9, 10]),\n",
    "    Conv2D(filters=8, kernel_size=3, strides=1, activation='relu'),\n",
    "    Conv2D(filters=2, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_9x9, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 28: 9x9 Input, 3x3x8 Kernel, 3x3x2 Kernel, 20 Dense, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 28\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[9, 9, 10]),\n",
    "    Conv2D(filters=8, kernel_size=3, strides=1, activation='relu'),\n",
    "    Conv2D(filters=2, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_9x9, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 29: 9x9 Input, 3x3x8 Kernel, 3x3x2 Kernel, 0.1 Dropout, 50 Dense, 0.1 Dropout, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 29\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[9, 9, 10]),\n",
    "    Conv2D(filters=8, kernel_size=3, strides=1, activation='relu'),\n",
    "    Conv2D(filters=2, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.1),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_9x9, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 30: 9x9 Input, 3x3x8 Kernel, 3x3x2 Kernel, 0.1 Dropout, 100 Dense, 0.1 Dropout, 50 Dense, 0.1 Dropout, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 30\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[9, 9, 10]),\n",
    "    Conv2D(filters=8, kernel_size=3, strides=1, activation='relu'),\n",
    "    Conv2D(filters=2, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.1),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_9x9, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 31: 7x7 Input, 3x3x12 Kernel, 0.1 Dropout, 50 Dense, 0.1 Dropout, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 31\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[7, 7, 10]),\n",
    "    Conv2D(filters=12, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.1),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_7x7, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 32: 7x7 Input, 3x3x20 Kernel, 0.1 Dropout, 50 Dense, 0.1 Dropout, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 32\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[7, 7, 10]),\n",
    "    Conv2D(filters=20, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.1),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_7x7, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 33: 7x7 Input, 3x3x20 Kernel, 0.2 Dropout, 100 Dense, 0.2 Dropout, 50 Dense, 0.2 Dropout, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 33\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[7, 7, 10]),\n",
    "    Conv2D(filters=20, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.2),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_7x7, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 34: 7x7 Input, 3x3x20 Kernel, 0.3 Dropout, 100 Dense, 0.3 Dropout, 50 Dense, 0.3 Dropout, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 34\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[7, 7, 10]),\n",
    "    Conv2D(filters=20, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.3),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_7x7, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 35: 7x7 Input, 3x3x20 Kernel, 0.25 Dropout, 100 Dense, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 35\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[7, 7, 10]),\n",
    "    Conv2D(filters=20, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.25),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_7x7, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 36: 7x7 Input, 3x3x20 Kernel, 0.2 Dropout, 75 Dense, 25 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 36\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[7, 7, 10]),\n",
    "    Conv2D(filters=20, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.2),\n",
    "    Dense(75, activation='relu'),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_7x7, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 37: 7x7 Input, 3x3x20 Kernel, 0.1 Dropout, 20 Dense, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 37\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[7, 7, 10]),\n",
    "    Conv2D(filters=20, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.1),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_7x7, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 38: 7x7 Input, 3x3x20 Kernel, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 38\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[7, 7, 10]),\n",
    "    Conv2D(filters=20, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_7x7, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 39: 7x7 Input, 3x3x20 Kernel, 0.1 Dropout, 10 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 39\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[7, 7, 10]),\n",
    "    Conv2D(filters=20, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.1),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_7x7, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 40: 7x7 Input, 3x3x20 Kernel, 0.15 Dropout, 20 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 40\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[7, 7, 10]),\n",
    "    Conv2D(filters=20, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.15),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_7x7, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 41: 7x7 Input, 3x3x20 Kernel, 0.1 Dropout, 25 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 41\n",
    "model[i] = Sequential([\n",
    "    InputLayer(input_shape=[7, 7, 10]),\n",
    "    Conv2D(filters=20, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.1),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model[i].summary()\n",
    "model[i].compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model[i].fit(\n",
    "    X_train_7x7, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(i)), earlystopping_cb])\n",
    "model[i].save(f'cnn_models/model_{i}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model: 39"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very good fit, comparably few parameters, fast training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    InputLayer(input_shape=[7, 7, 10]),\n",
    "    Conv2D(filters=20, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.1),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])\n",
    "model.summary()\n",
    "model.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])\n",
    "history = model.fit(\n",
    "    X_train_7x7, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=256, \n",
    "    validation_split=0.2,\n",
    "    verbose=0,\n",
    "    callbacks=[keras.callbacks.TensorBoard(get_run_logdir(0)), earlystopping_cb])\n",
    "model.save('../models/cnn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
