{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 20:12:10.130649: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-14 20:12:10.303807: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-14 20:12:10.305136: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-14 20:12:11.817305: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.random.set_seed(42)\n",
    "from keras.layers import InputLayer, Dense, Flatten, Conv2D, MaxPool2D\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_train = np.load('../data/indices_train.npy')\n",
    "# indices_test = np.load('../data/indices_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(874400, 4)\n"
     ]
    }
   ],
   "source": [
    "expanded_indices_train = np.repeat(indices_train, 25, axis=0)\n",
    "print(expanded_indices_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets = np.array([(i, j) for i in range(-2, 3) for j in range(-2, 3)])\n",
    "\n",
    "# Compute new width and height indices with offsets and ensure they're within valid bounds\n",
    "expanded_indices_train[:, 2] = np.clip(\n",
    "    np.repeat(indices_train[:, 2], 25) + np.tile(offsets[:, 0], len(indices_train)), 0, 1023\n",
    ")\n",
    "expanded_indices_train[:, 3] = np.clip(\n",
    "    np.repeat(indices_train[:, 3], 25) + np.tile(offsets[:, 1], len(indices_train)), 0, 1023\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = np.stack(list(map(lambda index: np.load(f'../data/images_train/image_{index:03d}.npy'), range(40))))\n",
    "y = np.stack(list(map(lambda index: np.load(f'../data/masks_train/mask_{index:03d}.npy'), range(40))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_full[expanded_indices_train[:, 0], :, expanded_indices_train[:, 2], expanded_indices_train[:, 3]]\n",
    "y_train = y[indices_train[:, 0], 0, indices_train[:, 2], indices_train[:, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_X_train = np.reshape(X_train, ((X_train.shape[0] // 25), 5, 5, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and standard deviation of the data\n",
    "mean = np.mean(reshaped_X_train)\n",
    "std = np.std(reshaped_X_train)\n",
    "\n",
    "# Normalize the data\n",
    "normalized_X_train = (reshaped_X_train - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    InputLayer(input_shape=[5, 5, 10]),\n",
    "    Conv2D(filters=3, kernel_size=3, strides=1, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 3)           273       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 1, 1, 3)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 3)                 0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                40        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324\n",
      "Trainable params: 324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mean_absolute_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 4.4925 - mean_absolute_error: 4.4925 - val_loss: 4.3542 - val_mean_absolute_error: 4.3542\n",
      "Epoch 2/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.4874 - mean_absolute_error: 4.4874 - val_loss: 4.3513 - val_mean_absolute_error: 4.3513\n",
      "Epoch 3/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.4857 - mean_absolute_error: 4.4857 - val_loss: 4.3497 - val_mean_absolute_error: 4.3497\n",
      "Epoch 4/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.4833 - mean_absolute_error: 4.4833 - val_loss: 4.3500 - val_mean_absolute_error: 4.3500\n",
      "Epoch 5/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.4827 - mean_absolute_error: 4.4827 - val_loss: 4.3460 - val_mean_absolute_error: 4.3460\n",
      "Epoch 6/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.4811 - mean_absolute_error: 4.4811 - val_loss: 4.3428 - val_mean_absolute_error: 4.3428\n",
      "Epoch 7/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.4814 - mean_absolute_error: 4.4814 - val_loss: 4.3447 - val_mean_absolute_error: 4.3447\n",
      "Epoch 8/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.4793 - mean_absolute_error: 4.4793 - val_loss: 4.3385 - val_mean_absolute_error: 4.3385\n",
      "Epoch 9/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.4760 - mean_absolute_error: 4.4760 - val_loss: 4.3484 - val_mean_absolute_error: 4.3484\n",
      "Epoch 10/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.4747 - mean_absolute_error: 4.4747 - val_loss: 4.3474 - val_mean_absolute_error: 4.3474\n",
      "Epoch 11/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.4753 - mean_absolute_error: 4.4753 - val_loss: 4.3314 - val_mean_absolute_error: 4.3314\n",
      "Epoch 12/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.4697 - mean_absolute_error: 4.4697 - val_loss: 4.3370 - val_mean_absolute_error: 4.3370\n",
      "Epoch 13/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.4716 - mean_absolute_error: 4.4716 - val_loss: 4.3325 - val_mean_absolute_error: 4.3325\n",
      "Epoch 14/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.4653 - mean_absolute_error: 4.4653 - val_loss: 4.3280 - val_mean_absolute_error: 4.3280\n",
      "Epoch 15/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.4647 - mean_absolute_error: 4.4647 - val_loss: 4.3262 - val_mean_absolute_error: 4.3262\n",
      "Epoch 16/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.4626 - mean_absolute_error: 4.4626 - val_loss: 4.3237 - val_mean_absolute_error: 4.3237\n",
      "Epoch 17/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.4629 - mean_absolute_error: 4.4629 - val_loss: 4.3234 - val_mean_absolute_error: 4.3234\n",
      "Epoch 18/100\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 4.4595 - mean_absolute_error: 4.4595 - val_loss: 4.3148 - val_mean_absolute_error: 4.3148\n",
      "Epoch 19/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.4540 - mean_absolute_error: 4.4540 - val_loss: 4.3208 - val_mean_absolute_error: 4.3208\n",
      "Epoch 20/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.4523 - mean_absolute_error: 4.4523 - val_loss: 4.3192 - val_mean_absolute_error: 4.3192\n",
      "Epoch 21/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.4507 - mean_absolute_error: 4.4507 - val_loss: 4.3085 - val_mean_absolute_error: 4.3085\n",
      "Epoch 22/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.4507 - mean_absolute_error: 4.4507 - val_loss: 4.3324 - val_mean_absolute_error: 4.3324\n",
      "Epoch 23/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.4511 - mean_absolute_error: 4.4511 - val_loss: 4.3177 - val_mean_absolute_error: 4.3177\n",
      "Epoch 24/100\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 4.4437 - mean_absolute_error: 4.4437 - val_loss: 4.3040 - val_mean_absolute_error: 4.3040\n",
      "Epoch 25/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.4495 - mean_absolute_error: 4.4495 - val_loss: 4.3012 - val_mean_absolute_error: 4.3012\n",
      "Epoch 26/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.4433 - mean_absolute_error: 4.4433 - val_loss: 4.3024 - val_mean_absolute_error: 4.3024\n",
      "Epoch 27/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.4420 - mean_absolute_error: 4.4420 - val_loss: 4.2967 - val_mean_absolute_error: 4.2967\n",
      "Epoch 28/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.4390 - mean_absolute_error: 4.4390 - val_loss: 4.2969 - val_mean_absolute_error: 4.2969\n",
      "Epoch 29/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.4381 - mean_absolute_error: 4.4381 - val_loss: 4.2967 - val_mean_absolute_error: 4.2967\n",
      "Epoch 30/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.4363 - mean_absolute_error: 4.4363 - val_loss: 4.2914 - val_mean_absolute_error: 4.2914\n",
      "Epoch 31/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.4335 - mean_absolute_error: 4.4335 - val_loss: 4.2960 - val_mean_absolute_error: 4.2960\n",
      "Epoch 32/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.4365 - mean_absolute_error: 4.4365 - val_loss: 4.2917 - val_mean_absolute_error: 4.2917\n",
      "Epoch 33/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.4278 - mean_absolute_error: 4.4278 - val_loss: 4.2985 - val_mean_absolute_error: 4.2985\n",
      "Epoch 34/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.4296 - mean_absolute_error: 4.4296 - val_loss: 4.2872 - val_mean_absolute_error: 4.2872\n",
      "Epoch 35/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.4287 - mean_absolute_error: 4.4287 - val_loss: 4.2914 - val_mean_absolute_error: 4.2914\n",
      "Epoch 36/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.4290 - mean_absolute_error: 4.4290 - val_loss: 4.3022 - val_mean_absolute_error: 4.3022\n",
      "Epoch 37/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.4292 - mean_absolute_error: 4.4292 - val_loss: 4.3252 - val_mean_absolute_error: 4.3252\n",
      "Epoch 38/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.4224 - mean_absolute_error: 4.4224 - val_loss: 4.2866 - val_mean_absolute_error: 4.2866\n",
      "Epoch 39/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 4.4221 - mean_absolute_error: 4.4221 - val_loss: 4.3258 - val_mean_absolute_error: 4.3258\n",
      "Epoch 40/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 4.4218 - mean_absolute_error: 4.4218 - val_loss: 4.2816 - val_mean_absolute_error: 4.2816\n",
      "Epoch 41/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 4.4201 - mean_absolute_error: 4.4201 - val_loss: 4.2867 - val_mean_absolute_error: 4.2867\n",
      "Epoch 42/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 4.4227 - mean_absolute_error: 4.4227 - val_loss: 4.2808 - val_mean_absolute_error: 4.2808\n",
      "Epoch 43/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 4.4209 - mean_absolute_error: 4.4209 - val_loss: 4.2934 - val_mean_absolute_error: 4.2934\n",
      "Epoch 44/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.4157 - mean_absolute_error: 4.4157 - val_loss: 4.2751 - val_mean_absolute_error: 4.2751\n",
      "Epoch 45/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.4169 - mean_absolute_error: 4.4169 - val_loss: 4.2742 - val_mean_absolute_error: 4.2742\n",
      "Epoch 46/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.4119 - mean_absolute_error: 4.4119 - val_loss: 4.2721 - val_mean_absolute_error: 4.2721\n",
      "Epoch 47/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.4102 - mean_absolute_error: 4.4102 - val_loss: 4.2773 - val_mean_absolute_error: 4.2773\n",
      "Epoch 48/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.4103 - mean_absolute_error: 4.4103 - val_loss: 4.2887 - val_mean_absolute_error: 4.2887\n",
      "Epoch 49/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.4091 - mean_absolute_error: 4.4091 - val_loss: 4.2818 - val_mean_absolute_error: 4.2818\n",
      "Epoch 50/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.4118 - mean_absolute_error: 4.4118 - val_loss: 4.3182 - val_mean_absolute_error: 4.3182\n",
      "Epoch 51/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.4078 - mean_absolute_error: 4.4078 - val_loss: 4.2763 - val_mean_absolute_error: 4.2763\n",
      "Epoch 52/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.4077 - mean_absolute_error: 4.4077 - val_loss: 4.2790 - val_mean_absolute_error: 4.2790\n",
      "Epoch 53/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.4085 - mean_absolute_error: 4.4085 - val_loss: 4.2718 - val_mean_absolute_error: 4.2718\n",
      "Epoch 54/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.4047 - mean_absolute_error: 4.4047 - val_loss: 4.2671 - val_mean_absolute_error: 4.2671\n",
      "Epoch 55/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.4045 - mean_absolute_error: 4.4045 - val_loss: 4.2871 - val_mean_absolute_error: 4.2871\n",
      "Epoch 56/100\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 4.4049 - mean_absolute_error: 4.4049 - val_loss: 4.2705 - val_mean_absolute_error: 4.2705\n",
      "Epoch 57/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 4.4009 - mean_absolute_error: 4.4009 - val_loss: 4.2725 - val_mean_absolute_error: 4.2725\n",
      "Epoch 58/100\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 4.4013 - mean_absolute_error: 4.4013 - val_loss: 4.2654 - val_mean_absolute_error: 4.2654\n",
      "Epoch 59/100\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 4.4003 - mean_absolute_error: 4.4003 - val_loss: 4.2652 - val_mean_absolute_error: 4.2652\n",
      "Epoch 60/100\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 4.3967 - mean_absolute_error: 4.3967 - val_loss: 4.2956 - val_mean_absolute_error: 4.2956\n",
      "Epoch 61/100\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 4.3997 - mean_absolute_error: 4.3997 - val_loss: 4.2731 - val_mean_absolute_error: 4.2731\n",
      "Epoch 62/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 4.4029 - mean_absolute_error: 4.4029 - val_loss: 4.2665 - val_mean_absolute_error: 4.2665\n",
      "Epoch 63/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 4.3961 - mean_absolute_error: 4.3961 - val_loss: 4.2680 - val_mean_absolute_error: 4.2680\n",
      "Epoch 64/100\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 4.3987 - mean_absolute_error: 4.3987 - val_loss: 4.2671 - val_mean_absolute_error: 4.2671\n",
      "Epoch 65/100\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 4.3932 - mean_absolute_error: 4.3932 - val_loss: 4.2953 - val_mean_absolute_error: 4.2953\n",
      "Epoch 66/100\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 4.3948 - mean_absolute_error: 4.3948 - val_loss: 4.2745 - val_mean_absolute_error: 4.2745\n",
      "Epoch 67/100\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 4.3975 - mean_absolute_error: 4.3975 - val_loss: 4.2652 - val_mean_absolute_error: 4.2652\n",
      "Epoch 68/100\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 4.3950 - mean_absolute_error: 4.3950 - val_loss: 4.2590 - val_mean_absolute_error: 4.2590\n",
      "Epoch 69/100\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 4.3892 - mean_absolute_error: 4.3892 - val_loss: 4.2688 - val_mean_absolute_error: 4.2688\n",
      "Epoch 70/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 4.3964 - mean_absolute_error: 4.3964 - val_loss: 4.2662 - val_mean_absolute_error: 4.2662\n",
      "Epoch 71/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 4.3928 - mean_absolute_error: 4.3928 - val_loss: 4.2621 - val_mean_absolute_error: 4.2621\n",
      "Epoch 72/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 4.3928 - mean_absolute_error: 4.3928 - val_loss: 4.2600 - val_mean_absolute_error: 4.2600\n",
      "Epoch 73/100\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 4.3872 - mean_absolute_error: 4.3872 - val_loss: 4.3085 - val_mean_absolute_error: 4.3085\n",
      "Epoch 74/100\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 4.3877 - mean_absolute_error: 4.3877 - val_loss: 4.2613 - val_mean_absolute_error: 4.2613\n",
      "Epoch 75/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 4.3844 - mean_absolute_error: 4.3844 - val_loss: 4.2585 - val_mean_absolute_error: 4.2585\n",
      "Epoch 76/100\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 4.3867 - mean_absolute_error: 4.3867 - val_loss: 4.2693 - val_mean_absolute_error: 4.2693\n",
      "Epoch 77/100\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 4.3822 - mean_absolute_error: 4.3822 - val_loss: 4.2802 - val_mean_absolute_error: 4.2802\n",
      "Epoch 78/100\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 4.3892 - mean_absolute_error: 4.3892 - val_loss: 4.2589 - val_mean_absolute_error: 4.2589\n",
      "Epoch 79/100\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 4.3826 - mean_absolute_error: 4.3826 - val_loss: 4.2556 - val_mean_absolute_error: 4.2556\n",
      "Epoch 80/100\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 4.3874 - mean_absolute_error: 4.3874 - val_loss: 4.2616 - val_mean_absolute_error: 4.2616\n",
      "Epoch 81/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.3790 - mean_absolute_error: 4.3790 - val_loss: 4.2681 - val_mean_absolute_error: 4.2681\n",
      "Epoch 82/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.3809 - mean_absolute_error: 4.3809 - val_loss: 4.2747 - val_mean_absolute_error: 4.2747\n",
      "Epoch 83/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.3847 - mean_absolute_error: 4.3847 - val_loss: 4.2545 - val_mean_absolute_error: 4.2545\n",
      "Epoch 84/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.3737 - mean_absolute_error: 4.3737 - val_loss: 4.2569 - val_mean_absolute_error: 4.2569\n",
      "Epoch 85/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.3764 - mean_absolute_error: 4.3764 - val_loss: 4.2724 - val_mean_absolute_error: 4.2724\n",
      "Epoch 86/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.3793 - mean_absolute_error: 4.3793 - val_loss: 4.2534 - val_mean_absolute_error: 4.2534\n",
      "Epoch 87/100\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 4.3738 - mean_absolute_error: 4.3738 - val_loss: 4.2642 - val_mean_absolute_error: 4.2642\n",
      "Epoch 88/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.3767 - mean_absolute_error: 4.3767 - val_loss: 4.2599 - val_mean_absolute_error: 4.2599\n",
      "Epoch 89/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.3786 - mean_absolute_error: 4.3786 - val_loss: 4.2474 - val_mean_absolute_error: 4.2474\n",
      "Epoch 90/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.3756 - mean_absolute_error: 4.3756 - val_loss: 4.2572 - val_mean_absolute_error: 4.2572\n",
      "Epoch 91/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 4.3696 - mean_absolute_error: 4.3696 - val_loss: 4.2468 - val_mean_absolute_error: 4.2468\n",
      "Epoch 92/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 4.3732 - mean_absolute_error: 4.3732 - val_loss: 4.2477 - val_mean_absolute_error: 4.2477\n",
      "Epoch 93/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 4.3745 - mean_absolute_error: 4.3745 - val_loss: 4.2868 - val_mean_absolute_error: 4.2868\n",
      "Epoch 94/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.3742 - mean_absolute_error: 4.3742 - val_loss: 4.2486 - val_mean_absolute_error: 4.2486\n",
      "Epoch 95/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.3678 - mean_absolute_error: 4.3678 - val_loss: 4.2499 - val_mean_absolute_error: 4.2499\n",
      "Epoch 96/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 4.3663 - mean_absolute_error: 4.3663 - val_loss: 4.2528 - val_mean_absolute_error: 4.2528\n",
      "Epoch 97/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 4.3742 - mean_absolute_error: 4.3742 - val_loss: 4.2447 - val_mean_absolute_error: 4.2447\n",
      "Epoch 98/100\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 4.3688 - mean_absolute_error: 4.3688 - val_loss: 4.2613 - val_mean_absolute_error: 4.2613\n",
      "Epoch 99/100\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 4.3669 - mean_absolute_error: 4.3669 - val_loss: 4.2529 - val_mean_absolute_error: 4.2529\n",
      "Epoch 100/100\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 4.3653 - mean_absolute_error: 4.3653 - val_loss: 4.2694 - val_mean_absolute_error: 4.2694\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(normalized_X_train, \n",
    "                    y_train, \n",
    "                    epochs=100, \n",
    "                    batch_size=256, \n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
